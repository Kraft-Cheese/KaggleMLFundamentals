{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be37d90-9bf7-4ed3-8d3e-ae74c942e016",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41f9d52-8d15-4e29-bd2a-e556f97d608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10394d14-2fe7-43be-8e50-a190d686b1c7",
   "metadata": {},
   "source": [
    "# Logistic Regression with TF-IDF Feature Extraction\n",
    "\n",
    "In this notebook we implement a logistic regression binary classifier performing feature extraction using TF-IDF\n",
    "For the logistic regression model we implemented the options for L1 and L2 regularization (though not yet elastic-net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733f63fe-2684-4f6b-b3df-1d5be2f04eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate: Learning rate for gradient descent.\n",
    "    n_iters: Number of iterations for training the model.\n",
    "    regularization: 'L1', 'L2', or None.\n",
    "    strength: Regularization strength.\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000, regularization=None, strength=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.regularization = regularization\n",
    "        self.strength = strength\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, array):\n",
    "        # Sigmoid function\n",
    "        return 1 / (1 + np.exp(-array))\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        # Cross-entropy loss with optional regularization\n",
    "        e = 1e-15  # Prevent log(0)\n",
    "        y_pred = np.clip(y_pred, e, 1 - e)\n",
    "        n_samples = y_true.shape[0]\n",
    "        # Cross-entropy loss\n",
    "        loss = - (1 / n_samples) *  np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        # Regularization\n",
    "        if self.regularization is not None and self.weights is not None:\n",
    "            if self.regularization == 'L1':\n",
    "                # L1 regularization\n",
    "                loss += (self.strength / n_samples) * np.sum(np.abs(self.weights))\n",
    "            elif self.regularization == 'L2':\n",
    "                # L2 regularization\n",
    "                loss += (self.strength / (2 * n_samples)) * np.sum(self.weights ** 2)\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the logistic regression model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features (NumPy array of shape (n_samples, n_features)).\n",
    "        - y: Labels (NumPy array of shape (n_samples,)).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0.0\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            # Linear model\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            # Predictions\n",
    "            y_pred = self.sigmoid(linear_model)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Regularization\n",
    "            if self.regularization == 'L1':\n",
    "                dw += (self.strength / n_samples) * np.sign(self.weights)\n",
    "            elif self.regularization == 'L2':\n",
    "                dw += (self.strength / n_samples) * self.weights\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Print loss every 100 iterations\n",
    "            if i % 100 == 0:\n",
    "                current_loss = self.loss(y, y_pred)\n",
    "                print(f'Loss after iteration {i}: {current_loss}')\n",
    "\n",
    "    def probability(self, X):\n",
    "        # Predict the probability of the input X\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(linear_model)\n",
    "\n",
    "    def predict(self, X, decision_boundary=0.5):\n",
    "        # Predict the class labels\n",
    "        prob = self.probability(X)\n",
    "        return (prob >= decision_boundary).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d334068-1bc6-4492-aa9f-eb28401c0061",
   "metadata": {},
   "source": [
    "# TF, IDF, Macro F1, Train and Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29755b52-a50f-44ed-8289-0a6d992b69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term_counts):\n",
    "    \"\"\"\n",
    "    Compute term frequency (TF).\n",
    "\n",
    "    Parameters:\n",
    "    - term_counts: NumPy array of shape (n_samples, n_features)\n",
    "\n",
    "    Returns:\n",
    "    - TF matrix.\n",
    "    \"\"\"\n",
    "    # Sum of terms in each document\n",
    "    doc_sum = np.sum(term_counts, axis=1, keepdims=True)\n",
    "    # Avoid division by zero\n",
    "    doc_sum[doc_sum == 0] = 1\n",
    "    # Compute TF\n",
    "    return term_counts / doc_sum\n",
    "\n",
    "def idf(term_counts):\n",
    "    \"\"\"\n",
    "    Compute inverse document frequency (IDF).\n",
    "\n",
    "    Parameters:\n",
    "    - term_counts: NumPy array of shape (n_samples, n_features)\n",
    "\n",
    "    Returns:\n",
    "    - IDF vector.\n",
    "    \"\"\"\n",
    "    n_samples = term_counts.shape[0]\n",
    "    # Document frequency: number of documents that contain each term\n",
    "    df = np.count_nonzero(term_counts > 0, axis=0)\n",
    "    # Avoid division by zero\n",
    "    df[df == 0] = 1\n",
    "    # Compute IDF\n",
    "    return np.log(n_samples / df)\n",
    "\n",
    "def tf_idf(idf_values, tf_values):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - idf_values: NumPy array of shape (n_features,)\n",
    "    - tf_values: NumPy array of shape (n_samples, n_features)\n",
    "\n",
    "    Returns:\n",
    "    - TF-IDF matrix.\n",
    "    \"\"\"\n",
    "    return tf_values * idf_values\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features.\n",
    "    - y: Labels.\n",
    "    - test_size: Proportion of the dataset to include in the test split.\n",
    "    - random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    # Shuffle data\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_shuffled = X[indices]\n",
    "    y_shuffled = y[indices]\n",
    "    # Split the data\n",
    "    split_idx = int(X.shape[0] * (1 - test_size))\n",
    "    X_train = X_shuffled[:split_idx]\n",
    "    X_test = X_shuffled[split_idx:]\n",
    "    y_train = y_shuffled[:split_idx]\n",
    "    y_test = y_shuffled[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the macro F1 score.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    - Macro F1 Score.\n",
    "    \"\"\"\n",
    "    classes = np.unique(y_true)\n",
    "    f1_scores = []\n",
    "\n",
    "    for c in classes:\n",
    "        # True positives, false positives, false negatives\n",
    "        tp = np.sum((y_true == c) & (y_pred == c))\n",
    "        fp = np.sum((y_true != c) & (y_pred == c))\n",
    "        fn = np.sum((y_true == c) & (y_pred != c))\n",
    "\n",
    "        # Avoid division by zero\n",
    "        e = 1e-15\n",
    "        precision = tp / (tp + fp + e)\n",
    "        recall = tp / (tp + fn + e)\n",
    "\n",
    "        # F1 score\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + e)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Return the average F1 score\n",
    "    return np.mean(f1_scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "297e9f3f-1a6b-42d2-8205-4a0964a54918",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data\n",
    "\n",
    "We load the training and test datasets, get the TF-IDF features, and scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f01a8d-492d-4a25-bd46-fe2060f72d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_train = np.load('data_train.npy', allow_pickle=True)\n",
    "data_test = np.load('data_test.npy', allow_pickle=True)\n",
    "labels_train = np.loadtxt('label_train.csv', delimiter=',', skiprows=1, usecols=1)\n",
    "\n",
    "# Compute term frequencies\n",
    "tf_train = tf(data_train)\n",
    "tf_test = tf(data_test)\n",
    "\n",
    "# Compute inverse document frequencies from training data\n",
    "idf_train = idf(data_train)\n",
    "\n",
    "# Compute TF-IDF features\n",
    "tfidf_train = tf_idf(idf_train, tf_train)\n",
    "tfidf_test = tf_idf(idf_train, tf_test)\n",
    "\n",
    "# Feature scaling: Standardize the features\n",
    "mean = np.mean(tfidf_train, axis=0)\n",
    "std = np.std(tfidf_train, axis=0)\n",
    "std[std == 0] = 1  # Avoid division by zero\n",
    "\n",
    "# Scale features\n",
    "tfidf_train_scaled = (tfidf_train - mean) / std\n",
    "tfidf_test_scaled = (tfidf_test - mean) / std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2780241c-1136-497b-8abb-a24061f74d3c",
   "metadata": {},
   "source": [
    "# Split Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a44a5c5-10b2-44c6-a086-06ae9e37e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    tfidf_train_scaled,\n",
    "    labels_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cf24f6e-6a49-431c-9df4-06eb9432b468",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "We tune hyperparameters such as the type of regularization used (none, L1, L2) and strength of regularization to find the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2686894b-4697-4114-8e53-ed1704d85b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with regularization: None, strength: 0.001\n",
      "Loss after iteration 0: 0.6931471805599451\n",
      "Loss after iteration 100: 0.3255051143593493\n",
      "Loss after iteration 200: 0.22353625588996912\n",
      "Loss after iteration 300: 0.17085016521873816\n",
      "Loss after iteration 400: 0.1384307609948136\n",
      "Loss after iteration 500: 0.11641004528338861\n",
      "Loss after iteration 600: 0.1004488980248962\n",
      "Loss after iteration 700: 0.08833546980923004\n",
      "Loss after iteration 800: 0.07882200716426395\n",
      "Loss after iteration 900: 0.07114996343554418\n",
      "Validation Macro F1 Score with regularization None, strength 0.001: 0.4916\n",
      "\n",
      "Training model with regularization: None, strength: 0.01\n",
      "Loss after iteration 0: 0.6931471805599451\n",
      "Loss after iteration 100: 0.3255051143593493\n",
      "Loss after iteration 200: 0.22353625588996912\n",
      "Loss after iteration 300: 0.17085016521873816\n",
      "Loss after iteration 400: 0.1384307609948136\n",
      "Loss after iteration 500: 0.11641004528338861\n",
      "Loss after iteration 600: 0.1004488980248962\n",
      "Loss after iteration 700: 0.08833546980923004\n",
      "Loss after iteration 800: 0.07882200716426395\n",
      "Loss after iteration 900: 0.07114996343554418\n",
      "Validation Macro F1 Score with regularization None, strength 0.01: 0.4916\n",
      "\n",
      "Training model with regularization: None, strength: 0.1\n",
      "Loss after iteration 0: 0.6931471805599451\n",
      "Loss after iteration 100: 0.3255051143593493\n",
      "Loss after iteration 200: 0.22353625588996912\n",
      "Loss after iteration 300: 0.17085016521873816\n",
      "Loss after iteration 400: 0.1384307609948136\n",
      "Loss after iteration 500: 0.11641004528338861\n",
      "Loss after iteration 600: 0.1004488980248962\n",
      "Loss after iteration 700: 0.08833546980923004\n",
      "Loss after iteration 800: 0.07882200716426395\n",
      "Loss after iteration 900: 0.07114996343554418\n",
      "Validation Macro F1 Score with regularization None, strength 0.1: 0.4916\n",
      "\n",
      "Training model with regularization: L1, strength: 0.001\n",
      "Loss after iteration 0: 0.6931473522979619\n",
      "Loss after iteration 100: 0.3255183158391153\n",
      "Loss after iteration 200: 0.22355473913433316\n",
      "Loss after iteration 300: 0.1708721638830016\n",
      "Loss after iteration 400: 0.13845542221271284\n",
      "Loss after iteration 500: 0.11643685795129716\n",
      "Loss after iteration 600: 0.10047752351463837\n",
      "Loss after iteration 700: 0.08836566221343116\n",
      "Loss after iteration 800: 0.07885358143272848\n",
      "Loss after iteration 900: 0.0711827748179705\n",
      "Validation Macro F1 Score with regularization L1, strength 0.001: 0.4916\n",
      "\n",
      "Training model with regularization: L1, strength: 0.01\n",
      "Loss after iteration 0: 0.6931488979401136\n",
      "Loss after iteration 100: 0.32563710495814785\n",
      "Loss after iteration 200: 0.22372104214415922\n",
      "Loss after iteration 300: 0.17107008368559812\n",
      "Loss after iteration 400: 0.1386772829796097\n",
      "Loss after iteration 500: 0.11667805980054594\n",
      "Loss after iteration 600: 0.10073501834429527\n",
      "Loss after iteration 700: 0.08863723689140711\n",
      "Loss after iteration 800: 0.07913757051727449\n",
      "Loss after iteration 900: 0.07147787634119712\n",
      "Validation Macro F1 Score with regularization L1, strength 0.01: 0.4921\n",
      "\n",
      "Training model with regularization: L1, strength: 0.1\n",
      "Loss after iteration 0: 0.6931643543616308\n",
      "Loss after iteration 100: 0.3268225799481274\n",
      "Loss after iteration 200: 0.22537948070703506\n",
      "Loss after iteration 300: 0.17304252649269414\n",
      "Loss after iteration 400: 0.14088694759319817\n",
      "Loss after iteration 500: 0.11907895151378141\n",
      "Loss after iteration 600: 0.1032966278952815\n",
      "Loss after iteration 700: 0.09133745190866827\n",
      "Loss after iteration 800: 0.08195972640569123\n",
      "Loss after iteration 900: 0.07440898185844959\n",
      "Validation Macro F1 Score with regularization L1, strength 0.1: 0.4935\n",
      "\n",
      "Training model with regularization: L2, strength: 0.001\n",
      "Loss after iteration 0: 0.6931471805666598\n",
      "Loss after iteration 100: 0.3255051441866468\n",
      "Loss after iteration 200: 0.22353632022095504\n",
      "Loss after iteration 300: 0.17085026121048805\n",
      "Loss after iteration 400: 0.13843088574083473\n",
      "Loss after iteration 500: 0.11641019632413781\n",
      "Loss after iteration 600: 0.10044907331218489\n",
      "Loss after iteration 700: 0.08833566761899227\n",
      "Loss after iteration 800: 0.0788222260244045\n",
      "Loss after iteration 900: 0.07115020207272985\n",
      "Validation Macro F1 Score with regularization L2, strength 0.001: 0.4916\n",
      "\n",
      "Training model with regularization: L2, strength: 0.01\n",
      "Loss after iteration 0: 0.6931471806270924\n",
      "Loss after iteration 100: 0.3255054126321023\n",
      "Loss after iteration 200: 0.22353689919886283\n",
      "Loss after iteration 300: 0.1708511251340418\n",
      "Loss after iteration 400: 0.1384320084511657\n",
      "Loss after iteration 500: 0.11641155568496905\n",
      "Loss after iteration 600: 0.10045065088946607\n",
      "Loss after iteration 700: 0.08833744789580565\n",
      "Loss after iteration 800: 0.078824195751594\n",
      "Loss after iteration 900: 0.07115234979002036\n",
      "Validation Macro F1 Score with regularization L2, strength 0.01: 0.4916\n",
      "\n",
      "Training model with regularization: L2, strength: 0.1\n",
      "Loss after iteration 0: 0.6931471812314176\n",
      "Loss after iteration 100: 0.32550809706482464\n",
      "Loss after iteration 200: 0.22354268888242396\n",
      "Loss after iteration 300: 0.17085976415224416\n",
      "Loss after iteration 400: 0.13844323517246326\n",
      "Loss after iteration 500: 0.1164251487080789\n",
      "Loss after iteration 600: 0.10046642583891384\n",
      "Loss after iteration 700: 0.0883552495703816\n",
      "Loss after iteration 800: 0.07884389163017896\n",
      "Loss after iteration 900: 0.07117382524240914\n",
      "Validation Macro F1 Score with regularization L2, strength 0.1: 0.4916\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "reg_types = [None, 'L1', 'L2']\n",
    "reg_strengths = [0.001, 0.01, 0.1]\n",
    "n_iters = 1000\n",
    "\n",
    "best_f1 = 0\n",
    "best_regularization = None\n",
    "best_strength = None\n",
    "best_model = None\n",
    "\n",
    "for reg in reg_types:\n",
    "    for strength in reg_strengths:\n",
    "        print(f\"\\nTraining model with regularization: {reg}, strength: {strength}\")\n",
    "        model = LogisticRegression(\n",
    "            learning_rate=learning_rate,\n",
    "            n_iters=n_iters,\n",
    "            regularization=reg,\n",
    "            strength=strength\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        val_predictions = model.predict(X_val)\n",
    "\n",
    "        f1 = macro_f1(y_val, val_predictions)\n",
    "        print(f\"Validation Macro F1 Score with regularization {reg}, strength {strength}: {f1:.4f}\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_regularization = reg\n",
    "            best_strength = strength\n",
    "            best_model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16120f5-d77e-47e0-9d52-47c4d61c48ef",
   "metadata": {},
   "source": [
    "# Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd307d1-046f-4859-ae40-24b523edebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best regularization: L1\n",
      "Best regularization strength: 0.1\n",
      "Best validation Macro F1 Score: 0.4935\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest regularization: {best_regularization}\")\n",
    "print(f\"Best regularization strength: {best_strength}\")\n",
    "print(f\"Best validation Macro F1 Score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ea2c2-1add-4f3e-b144-945cbf62fa81",
   "metadata": {},
   "source": [
    "# Retrain the Best Model on the Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb05921-f4a7-4102-9810-272237f23fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.6931592119807853\n",
      "Loss after iteration 100: 0.37050524705463544\n",
      "Loss after iteration 200: 0.2695306107363191\n",
      "Loss after iteration 300: 0.21295561690775755\n",
      "Loss after iteration 400: 0.17637312672339492\n",
      "Loss after iteration 500: 0.150727986596438\n",
      "Loss after iteration 600: 0.13173935798157227\n",
      "Loss after iteration 700: 0.11710604568372056\n",
      "Loss after iteration 800: 0.10547932237659026\n",
      "Loss after iteration 900: 0.0960165252807168\n"
     ]
    }
   ],
   "source": [
    "# Retrain the best model on the full training data\n",
    "best_model_full = LogisticRegression(\n",
    "    learning_rate=learning_rate,\n",
    "    n_iters=n_iters,\n",
    "    regularization=best_regularization,\n",
    "    strength=best_strength\n",
    ")\n",
    "best_model_full.fit(tfidf_train_scaled, labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f42325-36ef-4ce2-90d5-9c53c359b17d",
   "metadata": {},
   "source": [
    "# Predict on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069615f7-d5ea-4859-8ad6-20040b2e71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "test_predictions = best_model_full.predict(tfidf_test_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86a1d770-eb5d-4c18-a8bc-d44b97d05bad",
   "metadata": {},
   "source": [
    "# Save Predictions to CSV\n",
    "\n",
    "The predictions are then saved for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccb9070-05c1-4465-b127-fc794924bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for saving\n",
    "i = np.arange(len(test_predictions))\n",
    "output = np.column_stack((i, test_predictions))\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "header = 'Id,Label'\n",
    "np.savetxt('predictions.csv', output, delimiter=',', header=header, comments='', fmt='%d')\n",
    "print(\"\\nPredictions saved to predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f90528-7592-42ad-86ee-d664dae961ae",
   "metadata": {},
   "source": [
    "# Check CSV Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce98b5d-c494-4106-86e3-d6327745ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file has 2356 rows.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "data = np.genfromtxt('predictions.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = data.shape[0]\n",
    "\n",
    "print(f'The CSV file has {num_rows} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e84d9-3d7c-4850-915d-c8ccccc31c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
