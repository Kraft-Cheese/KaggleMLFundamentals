{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e95103-46ab-4aeb-80f4-6df7b9a9184c",
   "metadata": {},
   "source": [
    "# Kaggle competition 1\n",
    "\n",
    "## I) Creating hypothesis for relationships within data, visualizing the data, understanding and describing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb41a7f9-6ff7-4240-843a-b29c56cad113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb375e18-9f1f-4796-b436-d6de3e1549c2",
   "metadata": {},
   "source": [
    "### 1) Creating a DataFrame of the Data, visualizing contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00eb9dd4-97d7-4172-bc64-ad689e7ba25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency table for term: 00\n",
      "label          0     1\n",
      "00_present            \n",
      "0           7123  2297\n",
      "1              1     1\n",
      "\n",
      "\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "Label 0: There are 7,123 documents where the term \"00\" is absent (not present) and the label is 0.\n",
      "Label 1: There are 2,297 documents where the term \"00\" is absent and the label is 1.\n",
      "\n",
      "Label 0: There is 1 document where the term \"00\" is present and the label is 0.\n",
      "Label 1: There is 1 document where the term \"00\" is present and the label is 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_train = np.load('data_train.npy', allow_pickle = True)\n",
    "data_test = np.load('data_test.npy', allow_pickle = True)\n",
    "vocab_map = np.load('vocab_map.npy', allow_pickle=True)\n",
    "\n",
    "# Load labels_train from CSV and extract the 'label' column\n",
    "labels_train_df = pd.read_csv('label_train.csv')  # Assuming this is your labels file\n",
    "labels_train = labels_train_df['label'].values  # Extract the labels as a NumPy array\n",
    "\n",
    "# Convert training data to a DataFrame for visualization\n",
    "df_train = pd.DataFrame(data_train)\n",
    "\n",
    "# Add column names using vocab_map\n",
    "df_train.columns = vocab_map\n",
    "\n",
    "# Add the target labels to the DataFrame\n",
    "df_train['label'] = labels_train\n",
    "\n",
    "# Select a few important terms for creating contingency tables\n",
    "selected_terms = vocab_map[:1]  # Let's say we are analyzing the first 5 terms\n",
    "\n",
    "# Create contingency tables for each selected term\n",
    "for term in selected_terms:\n",
    "    # Convert term counts to binary (presence/absence)\n",
    "    df_train[term + '_present'] = df_train[term].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Generate a contingency table for the term\n",
    "    contingency_table = pd.crosstab(df_train[term + '_present'], df_train['label'])\n",
    "    \n",
    "    print(f\"Contingency table for term: {term}\")\n",
    "    print(contingency_table)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print('''\n",
    "Interpretation:\n",
    "\n",
    "Label 0: There are 7,123 documents where the term \"00\" is absent (not present) and the label is 0.\n",
    "Label 1: There are 2,297 documents where the term \"00\" is absent and the label is 1.\n",
    "\n",
    "Label 0: There is 1 document where the term \"00\" is present and the label is 0.\n",
    "Label 1: There is 1 document where the term \"00\" is present and the label is 1.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87ad2c-f38e-4142-b441-7d243548ddf1",
   "metadata": {},
   "source": [
    "### 2) Transform the data with TF-IDF and visualize the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef47c66-1992-43d0-95ac-af93674ff517",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "data_train_tfidf = tfidf_transformer.fit_transform(data_train)\n",
    "data_test_tfidf = tfidf_transformer.transform(data_test)\n",
    "\n",
    "# Convert the sparse matrix to a dense format (if needed)\n",
    "data_train_tfidf_dense = data_train_tfidf.toarray()\n",
    "\n",
    "# Create a DataFrame for easier visualization, with terms as column names\n",
    "df_tfidf = pd.DataFrame(data_train_tfidf_dense, columns=vocab_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a76cf8-d629-4f36-b3c7-866d2d7cea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9422, 26354)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(df_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae34feb-342e-4b42-97d2-ebefa176183b",
   "metadata": {},
   "source": [
    "## II) Dimensionalty reduction, and model selection\n",
    "\n",
    "### 1) Dimensionality reduction using truncated SVD, model selection using F1-score and fitting a simple logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14bb209-8a11-405c-b88d-b879089a4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:   9%|█████▎                                                     | 1/11 [00:10<01:41, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=500, Macro F1 Score=0.6504907660796119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  18%|██████████▋                                                | 2/11 [00:34<02:45, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=600, Macro F1 Score=0.6535555040606469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  27%|████████████████                                           | 3/11 [00:58<02:48, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=700, Macro F1 Score=0.6517923665849781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  36%|█████████████████████▍                                     | 4/11 [01:29<02:55, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=800, Macro F1 Score=0.6513715879166007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  45%|██████████████████████████▊                                | 5/11 [02:02<02:47, 27.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=900, Macro F1 Score=0.6495969182621277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  55%|████████████████████████████████▏                          | 6/11 [02:39<02:35, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1000, Macro F1 Score=0.6486245868592354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  64%|█████████████████████████████████████▌                     | 7/11 [03:40<02:42, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1100, Macro F1 Score=0.6488489480920974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  73%|██████████████████████████████████████████▉                | 8/11 [04:31<02:12, 44.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1200, Macro F1 Score=0.6516869522987132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  82%|████████████████████████████████████████████████▎          | 9/11 [05:55<01:52, 56.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1300, Macro F1 Score=0.6503540873568958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components:  91%|████████████████████████████████████████████████████▋     | 10/11 [06:52<00:56, 56.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1400, Macro F1 Score=0.6488226545575827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SVD Components: 100%|██████████████████████████████████████████████████████████| 11/11 [07:55<00:00, 43.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components=1500, Macro F1 Score=0.6508758865792623\n",
      "Best number of components: 600\n",
      "Best Macro F1 score: 0.6535555040606469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the range of components to test (broad range from 50 to 1500 with steps of 100)\n",
    "component_range = list(range(500, 1501, 100))  # Test from 500 to 1500 with steps of 100\n",
    "\n",
    "# Initialize lists to store results\n",
    "f1_scores = []\n",
    "\n",
    "# Define the scorer for macro F1 score\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Loop over different values for n_components with tqdm to show progress\n",
    "for n_components in tqdm(component_range, desc=\"Testing SVD Components\"):\n",
    "    # Apply Truncated SVD with n_components\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    X_reduced = svd.fit_transform(data_train_tfidf)\n",
    "    \n",
    "    # Initialize Logistic Regression\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation and calculate the average macro F1 score\n",
    "    scores = cross_val_score(clf, X_reduced, labels_train, cv=5, scoring=f1_scorer)\n",
    "    f1_scores.append(scores.mean())\n",
    "    \n",
    "    # Print the result for this number of components\n",
    "    print(f\"n_components={n_components}, Macro F1 Score={scores.mean()}\")\n",
    "\n",
    "# After loop, find the best number of components\n",
    "best_n_components = component_range[np.argmax(f1_scores)]\n",
    "print(f\"Best number of components: {best_n_components}\")\n",
    "print(f\"Best Macro F1 score: {max(f1_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ec152-4a38-4456-aea6-67bd6ac138f9",
   "metadata": {},
   "source": [
    "### 2) Keeping the 3rd best model (avoid over-fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa77ebcd-59c8-4f25-bf8c-b25a79e3b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Truncated SVD with 600 components\n",
    "svd_best = TruncatedSVD(n_components=1200, random_state=42)\n",
    "X_reduced_best = svd_best.fit_transform(data_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef70aac-5dc5-49b0-aecf-368f196bd736",
   "metadata": {},
   "source": [
    "### 3) Fitting different learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1ac286-9dc6-43da-a26d-61f41cf12392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (SVM): 0.694617681179871\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_clf = LinearSVC(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "svm_f1_scores = cross_val_score(svm_clf, X_reduced_best, labels_train, cv=5, scoring=f1_scorer)\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (SVM): {svm_f1_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab6d3c6-af13-4119-aa05-2de42ce15781",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 759, in fit\n    self._count(X, Y)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 881, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1689, in check_non_negative\n    raise ValueError(\"Negative values in data passed to %s\" % whom)\nValueError: Negative values in data passed to MultinomialNB (input X)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m nb_clf \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform 5-fold cross-validation for macro F1 score\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m nb_f1_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_reduced_best_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf1_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Print the average macro F1 score across the 5 folds\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validated Macro F1 Score (Naive Bayes on counts): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_f1_scores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mD:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mD:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mD:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 759, in fit\n    self._count(X, Y)\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 881, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"D:\\miniCondaa\\envs\\kaggle1IFT3395\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1689, in check_non_negative\n    raise ValueError(\"Negative values in data passed to %s\" % whom)\nValueError: Negative values in data passed to MultinomialNB (input X)\n"
     ]
    }
   ],
   "source": [
    "# Apply Truncated SVD with the raw count data\n",
    "svd = TruncatedSVD(n_components=1200, random_state=42)\n",
    "X_reduced_best_count = svd.fit_transform(data_train)  # Using raw count data without TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae14c0b1-910c-4b9b-947a-1dd16ec309d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (Naive Bayes on counts): 0.7104751581201816\n"
     ]
    }
   ],
   "source": [
    "# Set negative values to zero\n",
    "X_reduced_best_count[X_reduced_best_count < 0] = 0\n",
    "\n",
    "# Initialize Multinomial Naive Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "nb_f1_scores = cross_val_score(nb_clf, data_train, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (Naive Bayes on counts): {nb_f1_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31ecf37f-09b8-448f-a049-dab3630fe302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (Logistic Regression): 0.6516869522987132\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression\n",
    "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "log_f1_scores = cross_val_score(log_clf, X_reduced_best, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (Logistic Regression): {log_f1_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d2cb1c-eb18-4b8d-9c30-c0125715288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (Random Forest): 0.43412083789333844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "rf_f1_scores = cross_val_score(rf_clf, X_reduced_best, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (Random Forest): {rf_f1_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8c9517-1e91-4b01-aed9-250ed0deaa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (XGBoost): 0.6363559427423845\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "xgb_f1_scores = cross_val_score(xgb_clf, X_reduced_best, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (XGBoost): {xgb_f1_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989bb9e3-bf64-4508-8c9e-05a6be79c834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (MLP Classifier): 0.6850856935489185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize MLP Classifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "mlp_f1_scores = cross_val_score(mlp_clf, X_reduced_best, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (MLP Classifier): {mlp_f1_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3c27d4-6cb1-4248-91e0-f85152947a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Macro F1 Score (KNN): 0.5468534858136735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Perform 5-fold cross-validation for macro F1 score\n",
    "knn_f1_scores = cross_val_score(knn_clf, X_reduced_best, labels_train, cv=5, scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Print the average macro F1 score across the 5 folds\n",
    "print(f\"Cross-validated Macro F1 Score (KNN): {knn_f1_scores.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
